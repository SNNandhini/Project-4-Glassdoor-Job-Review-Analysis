{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go_eXkaQNMdV",
        "outputId": "a5b327a7-d56e-4756-baae-e0a9b79e5783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.39)] [Wa\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "\r0% [Waiting for headers] [2 InRelease 14.2 kB/114 kB 12%] [Waiting for headers]\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [2 InRelease 14.2 kB/114 kB 12%] [Waiting for headers]\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [2 InRelease 14.2 kB/114 kB 12%] [Waiting for headers]\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [2 InRelease 20.0 kB/114 kB 18%] [Waiting for headers]\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [2 InRelease 28.6 kB/114 kB 25%] [Connecting to ppa.la\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,297 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,970 kB]\n",
            "Fetched 4,602 kB in 3s (1,439 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.2.3'\n",
        "# spark_version = 'spark-<enter version>'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NLPPros\").getOrCreate()"
      ],
      "metadata": {
        "id": "X7eYep1pOCl3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "# Load in data into a DataFrame\n",
        "\n",
        "url = \"/content/reviews_nlp_input.csv\" #enter correct address here\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df = spark.read \\\n",
        "    .option(\"delimiter\", \"|\") \\\n",
        "    .option(\"multiline\", \"true\") \\\n",
        "    .option(\"quote\", \"\\\"\") \\\n",
        "    .option(\"escape\", \"\\\"\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .csv(url)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjtTU5AXUD_X",
        "outputId": "2783d72f-e60e-4fea-827a-589abb1ebe3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+-----------+--------------------+--------------------+--------------------+--------------+-----------------+--------------+-------------------+----------+-------------+-----------+---------+----------+-------+--------------------+--------------------+--------------------+\n",
            "|_c0|                firm|date_review|           job_title|             current|            location|overall_rating|work_life_balance|culture_values|diversity_inclusion|career_opp|comp_benefits|senior_mgmt|recommend|ceo_approv|outlook|            headline|                pros|                cons|\n",
            "+---+--------------------+-----------+--------------------+--------------------+--------------------+--------------+-----------------+--------------+-------------------+----------+-------------+-----------+---------+----------+-------+--------------------+--------------------+--------------------+\n",
            "|  0|AFH-Wealth-Manage...| 2020-10-01| Office Administr...|Former Employee, ...|Bromsgrove, Engla...|             2|              1.0|           3.0|                1.0|       1.0|          2.0|        2.0|        x|         o|      x|The people both m...|Great people in s...|Poor pay, huge ga...|\n",
            "|  1|AFH-Wealth-Manage...| 2021-02-05|     Quality Control|     Former Employee|Birmingham, Engla...|             1|              3.0|           1.0|                2.0|       1.0|          1.0|        1.0|        x|         o|      o|   Very low salaries|Majority of the p...|Salaries are much...|\n",
            "|  2|AFH-Wealth-Manage...| 2021-02-07|   IFA Administrator|Former Employee, ...|Bromsgrove, Engla...|             4|              3.0|           3.0|                4.0|       4.0|          4.0|        2.0|        v|         o|      v|                Good|Nice environment,...|Management can be...|\n",
            "|  3|AFH-Wealth-Manage...| 2021-02-07| Investment Opera...|Former Employee, ...|Birmingham, Engla...|             3|              5.0|           5.0|                4.0|       3.0|          1.0|        2.0|        x|         o|      v|          AFH Review|-Great People\\n-H...|-Low Salary\\n-Mid...|\n",
            "|  4|AFH-Wealth-Manage...| 2021-05-12| Client Engagemen...|Former Employee, ...|Birmingham, Engla...|             1|              1.0|           2.0|                1.0|       1.0|          1.0|        1.0|        x|         x|      x|Terrible- avoid l...|None, they lie ab...|-Unachievable bon...|\n",
            "|  5|AFH-Wealth-Manage...| 2021-05-13| Administrative A...|Former Employee, ...|Worcester, Englan...|             1|              1.0|           1.0|                1.0|       1.0|          1.0|        1.0|        x|         o|      r|         Steer clear|There are none to...|Borderline bullyi...|\n",
            "|  6|AFH-Wealth-Manage...| 2021-05-13| Mortgage and Pro...|Former Employee, ...|Taunton, England,...|             5|              5.0|           5.0|                5.0|       5.0|          4.0|        5.0|        o|         o|      o|    Mortgage Advisor|Good company to w...|Communication bet...|\n",
            "|  7|             AJ-Bell| 2020-10-14|     Admininistrator|Former Employee, ...|Manchester, Engla...|             3|              3.0|           3.0|                3.0|       4.0|          3.0|        3.0|        v|         v|      v|         Nice office|good company to w...|started to become...|\n",
            "|  8|             AJ-Bell| 2020-11-25|   YouInvest Advisor|Former Employee, ...|Salford, North We...|             3|              4.0|           1.0|                1.0|       1.0|          5.0|        3.0|        x|         v|      v|Good job, awful p...|AJ Bell is an exc...|Itâ€™s like a schoo...|\n",
            "|  9|             AJ-Bell| 2020-12-04|         Team Leader|Former Employee, ...|Manchester, Engla...|             1|              3.0|           1.0|                1.0|       2.0|          2.0|        1.0|        x|         r|      r|Shiny Office Cann...|If you're happy t...|First the minor p...|\n",
            "| 10|             AJ-Bell| 2020-12-08| Administrative A...|     Former Employee|Manchester, Engla...|             1|              3.0|           3.0|                4.0|       1.0|          2.0|        1.0|        x|         r|      r|Low pay, progress...|Nice offices and ...|Awful cronyism in...|\n",
            "| 11|             AJ-Bell| 2020-12-11|    Business Analyst|Current Employee,...|Manchester, Engla...|             4|              5.0|           5.0|                5.0|       5.0|          3.0|        5.0|        v|         v|      v| Great place to work|Great people and ...|Pension contribut...|\n",
            "| 12|             AJ-Bell| 2020-12-21|             Analyst|Former Employee, ...|London, England, ...|             2|              3.0|           2.0|                1.0|       3.0|          2.0|        1.0|        x|         v|      o|               Run!!|Great momentum af...|Poor salary, no f...|\n",
            "| 13|             AJ-Bell| 2021-01-05|      Credit Control|    Current Employee|Manchester, Engla...|             4|              5.0|           5.0|                5.0|       4.0|          5.0|        4.0|        v|         v|      v|Looked after but ...|Great employee be...|Feel like one of ...|\n",
            "| 14|             AJ-Bell| 2021-01-09|    CS Administrator|Current Employee,...|Manchester, Engla...|             4|              4.0|           5.0|                4.0|       5.0|          3.0|        4.0|        v|         v|      v|Lots of progressi...|Lots of internal ...|Pension contribut...|\n",
            "| 15|             AJ-Bell| 2021-01-14|   Customer Services|Former Employee, ...|Salford, North We...|             2|              4.0|           2.0|                2.0|       2.0|          2.0|        1.0|        x|         x|      x|             AJ Hell|everyone is in th...|Under staffed, po...|\n",
            "| 16|             AJ-Bell| 2021-01-25|             Manager|    Current Employee|Manchester, Engla...|             4|              5.0|           5.0|                4.0|       5.0|          4.0|        5.0|        v|         v|      v|Promotion, growin...|AJ Bell is one of...|Pension contribut...|\n",
            "| 17|             AJ-Bell| 2021-01-26| Customer Service...|Former Employee, ...|Salford, North We...|             1|              1.0|           1.0|                4.0|       1.0|          3.0|        1.0|        x|         r|      r| More cons than pros|Pay day drinks, C...|No consideration ...|\n",
            "| 18|             AJ-Bell| 2021-02-04| Operations Admin...|Former Employee, ...|Manchester, Engla...|             1|              5.0|           1.0|                4.0|       3.0|          1.0|        1.0|        x|         x|      x|             AJ Hell|Company drinks, g...|Salary\\nThe salar...|\n",
            "| 19|             AJ-Bell| 2021-02-05|      Administrative|Current Employee,...|Manchester, Engla...|             3|              2.0|           2.0|                2.0|       3.0|          3.0|        3.0|        o|         o|      o|                Okay|Near to home, gre...|Pay is not enough...|\n",
            "+---+--------------------+-----------+--------------------+--------------------+--------------------+--------------+-----------------+--------------+-------------------+----------+-------------+-----------+---------+----------+-------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform DataFrame to fit review_rating table"
      ],
      "metadata": {
        "id": "glufRc967zbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pros_df = df.select([\"pros\", \"overall_rating\", \"date_review\"])\n",
        "pros_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gtd69W-7y78",
        "outputId": "9164dbea-c5f4-47d9-9359-de2701abc8d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+-----------+\n",
            "|                pros|overall_rating|date_review|\n",
            "+--------------------+--------------+-----------+\n",
            "|Great people in s...|             2| 2020-10-01|\n",
            "|Majority of the p...|             1| 2021-02-05|\n",
            "|Nice environment,...|             4| 2021-02-07|\n",
            "|-Great People\\n-H...|             3| 2021-02-07|\n",
            "|None, they lie ab...|             1| 2021-05-12|\n",
            "|There are none to...|             1| 2021-05-13|\n",
            "|Good company to w...|             5| 2021-05-13|\n",
            "|good company to w...|             3| 2020-10-14|\n",
            "|AJ Bell is an exc...|             3| 2020-11-25|\n",
            "|If you're happy t...|             1| 2020-12-04|\n",
            "|Nice offices and ...|             1| 2020-12-08|\n",
            "|Great people and ...|             4| 2020-12-11|\n",
            "|Great momentum af...|             2| 2020-12-21|\n",
            "|Great employee be...|             4| 2021-01-05|\n",
            "|Lots of internal ...|             4| 2021-01-09|\n",
            "|everyone is in th...|             2| 2021-01-14|\n",
            "|AJ Bell is one of...|             4| 2021-01-25|\n",
            "|Pay day drinks, C...|             1| 2021-01-26|\n",
            "|Company drinks, g...|             1| 2021-02-04|\n",
            "|Near to home, gre...|             3| 2021-02-05|\n",
            "+--------------------+--------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_extract, length\n",
        "pros_df = df.withColumnRenamed(\"overall_rating\", \"label\").select([\"label\", \"date_review\", \"pros\"])\n",
        "pros_df = pros_df.withColumn('pros_length', length(pros_df['pros'])).dropna()\n",
        "pros_df.cache()\n",
        "pros_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbUWHiJL7u9p",
        "outputId": "7b2a7787-6c1c-4a00-c10d-fafbef17bb72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+--------------------+-----------+\n",
            "|label|date_review|                pros|pros_length|\n",
            "+-----+-----------+--------------------+-----------+\n",
            "|    2| 2020-10-01|Great people in s...|         63|\n",
            "|    1| 2021-02-05|Majority of the p...|         70|\n",
            "|    4| 2021-02-07|Nice environment,...|         48|\n",
            "|    3| 2021-02-07|-Great People\\n-H...|         52|\n",
            "|    1| 2021-05-12|None, they lie ab...|         61|\n",
            "|    1| 2021-05-13|There are none to...|         26|\n",
            "|    5| 2021-05-13|Good company to w...|         24|\n",
            "|    3| 2020-10-14|good company to w...|         38|\n",
            "|    3| 2020-11-25|AJ Bell is an exc...|         79|\n",
            "|    1| 2020-12-04|If you're happy t...|        480|\n",
            "|    1| 2020-12-08|Nice offices and ...|         44|\n",
            "|    4| 2020-12-11|Great people and ...|        129|\n",
            "|    2| 2020-12-21|Great momentum af...|         40|\n",
            "|    4| 2021-01-05|Great employee be...|         64|\n",
            "|    4| 2021-01-09|Lots of internal ...|        286|\n",
            "|    2| 2021-01-14|everyone is in th...|         68|\n",
            "|    4| 2021-01-25|AJ Bell is one of...|        530|\n",
            "|    1| 2021-01-26|Pay day drinks, C...|         71|\n",
            "|    1| 2021-02-04|Company drinks, g...|        105|\n",
            "|    3| 2021-02-05|Near to home, gre...|         26|\n",
            "+-----+-----------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Data Pipeline"
      ],
      "metadata": {
        "id": "eRn_r6ioMzOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "# Create all the features to the data set\n",
        "tokenizer = Tokenizer(inputCol=\"pros\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "metadata": {
        "id": "0Xogtj0eM1Jx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors (merge idf_token and review_length)\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'pros_length'], outputCol='features')"
      ],
      "metadata": {
        "id": "Kl9cWNnrNJRF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "metadata": {
        "id": "1ZgFTHUDNUZ0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform DataFrame"
      ],
      "metadata": {
        "id": "DNm0Erj6NdqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(pros_df)\n",
        "cleaned = cleaner.transform(pros_df)"
      ],
      "metadata": {
        "id": "Sq9MSa1ONfbd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show label of ham spam and resulting features\n",
        "cleaned.select(['label', 'features']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjTmcdeINxbl",
        "outputId": "926e55ed-0420-460c-8863-4b511e56a54f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    2|(262145,[19208,78...|\n",
            "|    1|(262145,[18700,58...|\n",
            "|    4|(262145,[5923,108...|\n",
            "|    3|(262145,[107107,1...|\n",
            "|    1|(262145,[16989,18...|\n",
            "|    1|(262145,[27576,58...|\n",
            "|    5|(262145,[27576,34...|\n",
            "|    3|(262145,[22346,27...|\n",
            "|    3|(262145,[10446,16...|\n",
            "|    1|(262145,[16551,16...|\n",
            "|    1|(262145,[19208,22...|\n",
            "|    4|(262145,[24980,47...|\n",
            "|    2|(262145,[9420,641...|\n",
            "|    4|(262145,[8500,177...|\n",
            "|    4|(262145,[3000,100...|\n",
            "|    2|(262145,[11104,27...|\n",
            "|    4|(262145,[1578,160...|\n",
            "|    1|(262145,[22371,95...|\n",
            "|    1|(262145,[22346,24...|\n",
            "|    3|(262145,[27576,74...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6CxE5FwPQ7U",
        "outputId": "b2c0a592-34a4-433c-f394-3f4e635112db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: string (nullable = true)\n",
            " |-- date_review: string (nullable = true)\n",
            " |-- pros: string (nullable = true)\n",
            " |-- pros_length: integer (nullable = true)\n",
            " |-- token_text: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- stop_tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- hash_token: vector (nullable = true)\n",
            " |-- idf_token: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "cleaned = cleaned.withColumn(\"label\", col(\"label\").cast(\"int\"))"
      ],
      "metadata": {
        "id": "oZJ9B_UyQVIt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run NaiveBayes"
      ],
      "metadata": {
        "id": "yX_4MVxWN5pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes() #labelCol='label', featuresCol='features'\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "cWJ_Wa6UN7Ux"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZuAIBe3Q5Vp",
        "outputId": "8d6a27a3-bafc-4487-9818-6eb6616475c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|label|date_review|                pros|pros_length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|\n",
            "+-----+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    1| 2020-09-12|None that I can c...|         28|[none, that, i, c...|        [none, come]|(262144,[19036,48...|(262144,[19036,48...|(262145,[19036,48...|\n",
            "|    1| 2020-09-12|Work from home is...|         31|[work, from, home...|  [work, home, pros]|(262144,[17893,34...|(262144,[17893,34...|(262145,[17893,34...|\n",
            "|    1| 2020-09-14|Lots of onboardin...|         53|[lots, of, onboar...|[lots, onboarding...|(262144,[27576,34...|(262144,[27576,34...|(262145,[27576,34...|\n",
            "|    1| 2020-09-14|Rate of pay and f...|         27|[rate, of, pay, a...|[rate, pay, flexi...|(262144,[68685,21...|(262144,[68685,21...|(262145,[68685,21...|\n",
            "|    1| 2020-09-14|They support the ...|         38|[they, support, t...|[support, psychia...|(262144,[11712,95...|(262144,[11712,95...|(262145,[11712,95...|\n",
            "|    1| 2020-09-14|great product, no...|         33|[great, product,,...|[great, product,,...|(262144,[5923,106...|(262144,[5923,106...|(262145,[5923,106...|\n",
            "|    1| 2020-09-15|Yes this is only ...|         42|[yes, this, is, o...|      [yes, interns]|(262144,[67416,95...|(262144,[67416,95...|(262145,[67416,95...|\n",
            "|    1| 2020-09-16|Decent hours, pai...|         48|[decent, hours,, ...|[decent, hours,, ...|(262144,[44923,53...|(262144,[44923,53...|(262145,[44923,53...|\n",
            "|    1| 2020-09-16|Deloitte is a pow...|        281|[deloitte, is, a,...|[deloitte, powerf...|(262144,[15682,27...|(262144,[15682,27...|(262145,[15682,27...|\n",
            "|    1| 2020-09-16|Exellent exposure...|         49|[exellent, exposu...|[exellent, exposu...|(262144,[27576,34...|(262144,[27576,34...|(262145,[27576,34...|\n",
            "|    1| 2020-09-16|Lots of opportuni...|         30|[lots, of, opport...|[lots, opportunit...|(262144,[27576,59...|(262144,[27576,59...|(262145,[27576,59...|\n",
            "|    1| 2020-09-16|free food all day...|         22|[free, food, all,...|[free, food, day,...|(262144,[42404,12...|(262144,[42404,12...|(262145,[42404,12...|\n",
            "|    1| 2020-09-17|Nothing, absolute...|         43|[nothing,, absolu...|[nothing,, absolu...|(262144,[27576,70...|(262144,[27576,70...|(262145,[27576,70...|\n",
            "|    1| 2020-09-17|There are no Pros...|         34|[there, are, no, ...|     [pros, working]|(262144,[58267,71...|(262144,[58267,71...|(262145,[58267,71...|\n",
            "|    1| 2020-09-18|You can work from...|        244|[you, can, work, ...|[work, anywhere, ...|(262144,[5121,174...|(262144,[5121,174...|(262145,[5121,174...|\n",
            "|    1| 2020-09-18|getting to know p...|         38|[getting, to, kno...|[getting, know, p...|(262144,[27576,49...|(262144,[27576,49...|(262145,[27576,49...|\n",
            "|    1| 2020-09-18|good salary and f...|         38|[good, salary, an...|[good, salary, fl...|(262144,[71450,96...|(262144,[71450,96...|(262145,[71450,96...|\n",
            "|    1| 2020-09-18|great benefits, g...|         37|[great, benefits,...|[great, benefits,...|(262144,[17648,22...|(262144,[17648,22...|(262145,[17648,22...|\n",
            "|    1| 2020-09-19|Discount on food....|         42|[discount, on, fo...|[discount, food.....|(262144,[30950,67...|(262144,[30950,67...|(262145,[30950,67...|\n",
            "|    1| 2020-09-19|Fast learn and lo...|         30|[fast, learn, and...|[fast, learn, lon...|(262144,[113503,1...|(262144,[113503,1...|(262145,[113503,1...|\n",
            "+-----+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkxwCl0iRBtH",
        "outputId": "f8d90aef-42dc-4f82-b65c-f763386e8bd9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|label|date_review|                pros|pros_length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|    1| 2020-09-13|I hated this job ...|         24|[i, hated, this, ...|  [hated, job, much]|(262144,[19036,76...|(262144,[19036,76...|(262145,[19036,76...|[-262.22966260422...|[0.99999953910250...|       0.0|\n",
            "|    1| 2020-09-14|Aucun malheureuse...|         71|[aucun, malheureu...|[aucun, malheureu...|(262144,[26980,44...|(262144,[26980,44...|(262145,[26980,44...|[-1424.3089985523...|[0.85089471348092...|       0.0|\n",
            "|    1| 2020-09-15|highly competitiv...|         46|[highly, competit...|[highly, competit...|(262144,[13090,19...|(262144,[13090,19...|(262145,[13090,19...|[-512.65219241796...|[0.00110426454644...|       1.0|\n",
            "|    1| 2020-09-16|It pays you somet...|         30|[it, pays, you, s...|[pays, something,...|(262144,[12590,19...|(262144,[12590,19...|(262145,[12590,19...|[-301.50620211235...|[0.02114301158657...|       2.0|\n",
            "|    1| 2020-09-18|Enough hours to e...|         33|[enough, hours, t...|[enough, hours, e...|(262144,[12168,27...|(262144,[12168,27...|(262145,[12168,27...|[-274.24125723116...|[1.82759086165527...|       2.0|\n",
            "+-----+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict accuracy of the model"
      ],
      "metadata": {
        "id": "p1_ASmd-ROIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting pros was: %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDPkxcUYRF6T",
        "outputId": "12ca0334-4d55-49f7-a8a2-301a1d5538e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting pros was: 0.191763\n"
          ]
        }
      ]
    }
  ]
}